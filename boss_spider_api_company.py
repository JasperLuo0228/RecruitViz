import asyncio
import csv
import json
import random
import os
from playwright.async_api import async_playwright

FIELDS = ["å…³é”®è¯", "èŒä½", "è–ªèµ„", "åŸå¸‚", "å…¬å¸", "ç»éªŒ", "å­¦å†", "å…¬å¸è§„æ¨¡", "åœ¨æ‹›èŒä½æ•°"]

class BossSpiderFastCompany:
    def __init__(self):
        self.cookie_file = "boss_cookies.json"
        self.output_file = "BOSSç›´è˜_å‰åŠæ•°æ®.csv"
        self.max_retries = 3
        self.request_delay = (1, 3)       # é¡µé—´éš”åŠ å¿«
        self.company_delay = (8, 18)         # å…¬å¸é¡µé‡‡é›†ååŠ å¿«
        self.keyword_delay = (10, 20)        # å…³é”®è¯é—´éš”
        self.batch_pause = 45              # æ¯100æ¡æš‚åœ
        self.batch_sleep = 30              # ä¼‘æ¯æ—¶é—´

    async def save_cookies(self, context):
        cookies = await context.cookies()
        with open(self.cookie_file, "w") as f:
            json.dump(cookies, f)

    async def load_cookies(self, context):
        try:
            with open(self.cookie_file, "r") as f:
                await context.add_cookies(json.load(f))
            return True
        except:
            return False

    async def ensure_login(self, context):
        for attempt in range(self.max_retries):
            test_url = "https://www.zhipin.com/wapi/zpgeek/search/joblist.json?query=æµ‹è¯•&page=1"
            response = await context.request.get(test_url)
            if response.status == 200:
                try:
                    data = await response.json()
                    if data.get('zpData', {}).get('jobList') is not None:
                        return True
                except:
                    pass
            print(f"ğŸ”„ ä¼šè¯å¤±æ•ˆï¼Œæ‰«ç ç™»å½•BOSSç›´è˜ï¼ˆç¬¬{attempt+1}æ¬¡ï¼‰")
            page = await context.new_page()
            await page.goto("https://www.zhipin.com/web/geek/job?query=æµ‹è¯•")
            await page.wait_for_timeout(60000)
            await self.save_cookies(context)
            await page.close()
        return False

    async def get_company_info(self, context, company):
        company_size, hiring_count = "", ""
        if not company:
            return company_size, hiring_count
        page = await context.new_page()
        try:
            await page.goto(f"https://www.zhipin.com/web/geek/job?query={company}", timeout=20000)
            await page.wait_for_timeout(1000)
            tags = await page.locator('span.company-info-tag').all_text_contents()
            company_size = next((tag for tag in tags if "äºº" in tag), "")
            try:
                hiring_count = await page.locator('span.count-text').first.text_content()
            except:
                hiring_count = ""
        except Exception as e:
            print(f"âš ï¸ å…¬å¸ä¸»é¡µé‡‡é›†å¼‚å¸¸: {e}")
            await asyncio.sleep(30)
        await page.close()
        await asyncio.sleep(random.uniform(*self.company_delay))
        return company_size, hiring_count

    async def fetch_job_page(self, context, keyword, page_num):
        url = f"https://www.zhipin.com/wapi/zpgeek/search/joblist.json?query={keyword}&city=101010100&page={page_num}"
        for attempt in range(self.max_retries):
            try:
                response = await context.request.get(url)
                if response.status != 200:
                    raise Exception(f"HTTP {response.status}")
                data = await response.json()
                if not data.get('zpData', {}).get('jobList'):
                    raise Exception("æ— æ•ˆçš„æ¥å£å“åº”")
                return data['zpData']['jobList']
            except Exception as e:
                print(f"âš ï¸ {keyword} ç¬¬{page_num}é¡µç¬¬{attempt+1}æ¬¡å¤±è´¥: {str(e)}")
                if attempt == self.max_retries - 1:
                    return None
                await asyncio.sleep(30)
                await self.ensure_login(context)

    async def run(self):
        async with async_playwright() as p:
            browser = await p.chromium.launch(
                headless=T,
                channel="chrome",
                args=[
                    "--disable-blink-features=AutomationControlled",
                    f"--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/{random.randint(90,110)}.0.0.0 Safari/537.36"
                ]
            )
            context = await browser.new_context(
                viewport={"width": 1366, "height": 768},
                locale="zh-CN"
            )

            if not await self.load_cookies(context) or not await self.ensure_login(context):
                print("âŒ ç™»å½•å¤±è´¥ï¼Œè¯·æ‰‹åŠ¨æ‰«ç ")
                await browser.close()
                return

            existing = set()
            if os.path.exists(self.output_file):
                with open(self.output_file, newline="", encoding="utf-8-sig") as ff:
                    reader = csv.DictReader(ff)
                    for row in reader:
                        existing.add((row['å…³é”®è¯'], row['èŒä½'], row['å…¬å¸']))

            keywords = ["æ‰˜è‚²", "å®¶æ”¿", "å…»è€", "åº·å¤", "è‚²å©´", "æ¯å©´", "æŠ¤ç†å‘˜", "æŠ¤ç†ä¸“ä¸š", "å…»è€æŠ¤ç†", "æ®¡è‘¬", "ä¸´ç»ˆå…³æ€€", "å©šå®´ç­–åˆ’", "å®¶å®´ç®¡å®¶", "å®´ä¼šä¸»æŒ",
                        "æ™ºæ…§å…»è€", "æ™ºèƒ½å…»è€", "æ™ºèƒ½æŠ¤ç†", "å¥åº·ç®¡ç†", "å¥åº·ç…§æŠ¤", "å…»è€é¡¾é—®", "ç¤¾åŒºå…»è€", "å±…å®¶å…»è€", "å…»è€è¿è¥", "å…»è€é™¢é™¢é•¿",
                        "è€å¹´äººæœåŠ¡", "è€å¹´å¥åº·", "åº·å…»", "åŒ»ç–—æŠ¤ç†", "æŠ¤ç†å­¦", "åŒ»å…»ç»“åˆ", "ä¸´åºŠæŠ¤ç†", "ä¸“ç§‘æŠ¤å£«", "æŠ¤å£«é•¿", "åŒ»ç–—æœåŠ¡",
                        "ç®¡å®¶", "å®¶æ”¿ç»ç†", "ä¿å§†", "æœˆå«‚", "è‚²å„¿å«‚", "å®¶æ”¿ç£å¯¼", "å®¶æ”¿é¡¹ç›®ç»ç†", "å±…å®¶ç…§æŠ¤", "ç”Ÿæ´»åŠ©ç†",
                        "æ‰˜ç­è€å¸ˆ", "æ‰˜è‚²è€å¸ˆ", "æ—©æ•™è€å¸ˆ", "äº²å­å›­", "å¹¼æ•™", "å¹¼æ‰˜", "æ—©æ•™ä¸­å¿ƒ", "å„¿ç«¥ç…§æŠ¤", "å¹¼å„¿å›­ä¿è‚²å‘˜", "å©´å¹¼å„¿å‘å±•", "å©´å¹¼å„¿æ—©æ•™",
                        "ç…§æŠ¤", "ç…§æŠ¤å¸ˆ", "å¥åº·ç…§æŠ¤å¸ˆ", "æŠ¤ç†åŠ©ç†", "è€äººé™ªæŠ¤", "æŠ¤å·¥", "é™¢é•¿åŠ©ç†", "ç¤¾åŒºç…§æŠ¤", "å…»è€åŸ¹è®­", "å¤±èƒ½è€äººç…§æŠ¤",
                        "åº·å¤æ²»ç–—å¸ˆ", "åº·å¤å¸ˆ", "å…»ç”Ÿé¡¾é—®", "ä¸­åŒ»æŠ¤ç†", "è€å¹´äº§ä¸š"]
            file_exists = os.path.exists(self.output_file)
            f = open(self.output_file, "a", newline="", encoding="utf-8-sig")
            writer = csv.writer(f)
            if not file_exists:
                writer.writerow(FIELDS)

            all_count = 0
            for keyword in keywords:
                print(f"\nğŸ” é‡‡é›†å…³é”®è¯: {keyword}")
                page_num = 1
                total = 0
                while page_num <= 30:
                    jobs = await self.fetch_job_page(context, keyword, page_num)
                    if not jobs:
                        print(f"â¹ï¸ {keyword} é‡‡é›†ç»ˆæ­¢äºç¬¬{page_num}é¡µ")
                        break
                    for job in jobs:
                        job_name = job.get("jobName", "")
                        salary = job.get("salaryDesc", "")
                        city = job.get("cityName", "")
                        company = job.get("brandName", "")
                        experience = job.get("jobExperience", "")
                        degree = job.get("jobDegree", "")

                        company_size, hiring_count = await self.get_company_info(context, company)

                        key = (keyword, job_name, company)
                        if key not in existing:
                            writer.writerow([
                                keyword, job_name, salary, city, company,
                                experience, degree, company_size, hiring_count
                            ])
                            f.flush()
                            existing.add(key)
                            total += 1
                            all_count += 1
                            print(f"âœ… {keyword} ç¬¬{page_num}é¡µ | æœ¬é¡µ{len(jobs)} | ç´¯è®¡{total} | æ€»{all_count}")

                            if all_count % self.batch_pause == 0:
                                print(f"â³ è¾¾åˆ°{self.batch_pause}æ¡ï¼Œè‡ªåŠ¨ä¼‘æ¯{self.batch_sleep}ç§’")
                                await asyncio.sleep(self.batch_sleep)

                        if all_count % self.batch_pause == 0:
                            print(f"â³ è¾¾åˆ°{self.batch_pause}æ¡ï¼Œè‡ªåŠ¨ä¼‘æ¯{self.batch_sleep}ç§’")
                            await asyncio.sleep(self.batch_sleep)

                    page_num += 1
                    await asyncio.sleep(random.uniform(*self.request_delay))

                await asyncio.sleep(random.uniform(*self.keyword_delay))
            f.close()
            await browser.close()
            print("\nğŸ‰ é‡‡é›†å®Œæˆï¼æ•°æ®å·²å®æ—¶ä¿å­˜")

if __name__ == "__main__":
    spider = BossSpiderFastCompany()
    asyncio.run(spider.run())
